<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Explainable AI: The Architect of Trust</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700;900&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #0F172A;
            color: #E2E8F0;
        }
        #background-canvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -1;
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 600px;
            margin-left: auto;
            margin-right: auto;
            height: 400px;
            max-height: 450px;
        }
        @media (max-width: 768px) {
            .chart-container {
                height: 350px;
            }
        }
        .gradient-text {
            background: linear-gradient(90deg, #38BDF8, #A78BFA, #F472B6);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .flow-step {
            display: flex;
            align-items: center;
            text-align: center;
            flex-direction: column;
        }
        .flow-arrow::after {
            content: '‚Üí';
            font-size: 2.5rem;
            color: #A78BFA;
            margin: 1rem 0;
        }
        @media (min-width: 768px) {
            .flow-arrow::after {
                content: '‚Üí';
                margin: 0 1rem;
            }
            .flow-step {
                flex-direction: row;
            }
        }
        /* Team Section Styling - Corrected Blob Shape */
        .team-member {
            text-align: center;
        }
        .blob-container {
            width: 150px;
            height: 150px;
            margin: 0 auto;
            position: relative;
            overflow: hidden; /* This is key to clip the image */
            transition: all 0.3s ease-in-out;
            /* Blob shape using border-radius on the container */
            border-radius: 47% 53% 70% 30% / 30% 43% 57% 70%;
        }
        .blob-container:hover {
            transform: scale(1.05);
            /* Change blob shape on hover for a dynamic effect */
            border-radius: 30% 70% 43% 57% / 57% 30% 70% 43%;
            box-shadow: 0 0 25px rgba(167, 139, 250, 0.5);
        }
        .blob-image {
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        /* Animation Styles */
        .reveal-on-scroll {
            opacity: 0;
            transform: translateY(30px);
            transition: opacity 0.6s ease-out, transform 0.6s ease-out;
            will-change: opacity, transform;
        }
        
        .revealed {
            opacity: 1;
            transform: translateY(0);
        }
    </style>
</head>
<body>
    <canvas id="background-canvas"></canvas>
    <main class="container mx-auto px-4 py-12 md:py-20">

        <header class="text-center mb-20 md:mb-32">
            <h1 class="text-4xl md:text-6xl font-black text-white leading-tight mb-4 reveal-on-scroll">Beyond the Algorithm</h1>
            <p class="text-xl md:text-2xl font-semibold gradient-text reveal-on-scroll" data-delay="200">Explainable AI as the Architect of Trust</p>
        </header>

        <section id="problem" class="mb-20 md:mb-32">
            <div class="text-center max-w-3xl mx-auto mb-12 reveal-on-scroll">
                <h2 class="text-3xl md:text-4xl font-bold text-white mb-4">The Shadow of Opacity</h2>
                <p class="text-lg text-slate-400">The most powerful AI models operate as "black boxes," where the "what" of their decisions is visible, but the "why" remains hidden. This opacity leads to the "Clever Hans" effect‚Äîright answers for wrong reasons‚Äîcausing tangible harm, perpetuating bias, and creating a dangerous accountability gap.</p>
            </div>
            <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8">
                <div class="bg-slate-800 p-6 rounded-xl shadow-lg border border-slate-700 reveal-on-scroll" data-delay="100">
                    <div class="text-3xl mb-3">üè•</div>
                    <h3 class="font-bold text-xl text-cyan-400 mb-2">Systemic Healthcare Bias</h3>
                    <p>An algorithm denied care to Black patients by using "lower historical cost" as a flawed proxy for "healthier," turning societal bias into digital discrimination.</p>
                </div>
                <div class="bg-slate-800 p-6 rounded-xl shadow-lg border border-slate-700 reveal-on-scroll" data-delay="200">
                    <div class="text-3xl mb-3">‚öñÔ∏è</div>
                    <h3 class="font-bold text-xl text-cyan-400 mb-2">Unjust Legal Outcomes</h3>
                    <p>The COMPAS recidivism tool flagged Black defendants as high-risk at nearly double the rate of white defendants, influencing harsher sentences without recourse.</p>
                </div>
                <div class="bg-slate-800 p-6 rounded-xl shadow-lg border border-slate-700 md:col-span-2 lg:col-span-1 reveal-on-scroll" data-delay="300">
                    <div class="text-3xl mb-3">üí∞</div>
                    <h3 class="font-bold text-xl text-cyan-400 mb-2">Biased Financial Decisions</h3>
                    <p>Opaque models in lending and hiring can learn to discriminate based on gender or race from historical data, perpetuating inequality under a veil of objectivity.</p>
                </div>
            </div>
        </section>

        <section id="solution" class="mb-20 md:mb-32">
            <div class="text-center max-w-3xl mx-auto mb-12 reveal-on-scroll">
                <h2 class="text-3xl md:text-4xl font-bold text-white mb-4">The Solution: The Four Pillars of XAI</h2>
                <p class="text-lg text-slate-400">Explainable AI (XAI) provides the methods to make AI understandable. It builds trustworthy AI on a foundation of core principles that transform opaque systems into collaborative partners, fostering the informed confidence needed for widespread adoption.</p>
            </div>
            <div class="grid grid-cols-1 md:grid-cols-2 gap-8 text-center max-w-4xl mx-auto">
                <div class="bg-slate-800 p-8 rounded-xl shadow-lg border border-slate-700 reveal-on-scroll" data-delay="100">
                    <div class="text-5xl mb-4">ü§ù</div>
                    <h3 class="font-bold text-xl text-white mb-2">Trust & Confidence</h3>
                    <p class="text-slate-400">Fosters user confidence by making complex model conclusions comprehensible.</p>
                </div>
                <div class="bg-slate-800 p-8 rounded-xl shadow-lg border border-slate-700 reveal-on-scroll" data-delay="200">
                    <div class="text-5xl mb-4">üõ°Ô∏è</div>
                    <h3 class="font-bold text-xl text-white mb-2">Accountability & Recourse</h3>
                    <p class="text-slate-400">Links decisions to organizations, enabling a "right to explanation" for affected individuals.</p>
                </div>
                <div class="bg-slate-800 p-8 rounded-xl shadow-lg border border-slate-700 reveal-on-scroll" data-delay="300">
                    <div class="text-5xl mb-4">‚öñÔ∏è</div>
                    <h3 class="font-bold text-xl text-white mb-2">Fairness & Bias Mitigation</h3>
                    <p class="text-slate-400">Uncovers and helps correct hidden biases learned from historical data.</p>
                </div>
                <div class="bg-slate-800 p-8 rounded-xl shadow-lg border border-slate-700 reveal-on-scroll" data-delay="400">
                    <div class="text-5xl mb-4">‚öôÔ∏è</div>
                    <h3 class="font-bold text-xl text-white mb-2">Safety & Model Improvement</h3>
                    <p class="text-slate-400">Helps verify model behavior, identify vulnerabilities, and effectively debug errors.</p>
                </div>
            </div>
        </section>

        <section id="toolkit" class="mb-20 md:mb-32">
            <div class="text-center max-w-3xl mx-auto mb-12 reveal-on-scroll">
                <h2 class="text-3xl md:text-4xl font-bold text-white mb-4">The AI Interpreter's Toolkit</h2>
                <p class="text-lg text-slate-400">XAI offers a suite of powerful techniques that act as "interpreters," translating complex algorithmic decisions. The choice of tool involves a trade-off between flexibility, theoretical soundness, and computational cost.</p>
            </div>
            <div class="grid grid-cols-1 md:grid-cols-2 gap-8 items-center">
                <div class="bg-slate-800 p-6 rounded-xl shadow-lg border border-slate-700 reveal-on-scroll" data-delay="100">
                    <h3 class="font-bold text-2xl text-violet-400 mb-3">Comparing Foundational Techniques</h3>
                    <p class="text-slate-400 mb-6">This radar chart compares three pillar techniques across key attributes. LIME offers flexibility, SHAP provides theoretical guarantees, and Grad-CAM excels at visual intuition for image models.</p>
                    <ul class="space-y-3 text-slate-300">
                        <li><span class="font-bold text-white">LIME:</span> "The Quick Poll." Fast and intuitive for local explanations of any model.</li>
                        <li><span class="font-bold text-white">SHAP:</span> "The Economic Audit." Robust and consistent, providing both local and global insights based on game theory.</li>
                        <li><span class="font-bold text-white">Grad-CAM:</span> "The Heatmap." Efficiently provides visual justification for CNN-based image classifications.</li>
                    </ul>
                </div>
                <div class="chart-container h-96 md:h-[450px] reveal-on-scroll" data-delay="200">
                    <canvas id="xaiTechniquesChart"></canvas>
                </div>
            </div>
        </section>

        <section id="impact" class="mb-20 md:mb-32">
            <div class="text-center max-w-3xl mx-auto mb-12 reveal-on-scroll">
                <h2 class="text-3xl md:text-4xl font-bold text-white mb-4">XAI in Action: Global & Indian Impact</h2>
                <p class="text-lg text-slate-400">From global finance to local agriculture, XAI is delivering tangible benefits by enhancing efficiency and building the trust necessary for widespread adoption of AI-powered solutions.</p>
            </div>
            <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                <div class="bg-slate-800 p-6 rounded-xl shadow-lg border border-slate-700 md:col-span-2 reveal-on-scroll">
                     <h3 class="font-bold text-2xl text-white mb-4 text-center">Measurable Improvements in Key Sectors</h3>
                     <p class="text-center text-slate-400 mb-4">XAI drives concrete outcomes. The chart below illustrates the positive impact reported in several key areas, showing how transparency leads to better performance and higher user confidence.</p>
                    <div class="chart-container h-96">
                        <canvas id="impactChart"></canvas>
                    </div>
                </div>
                <div class="bg-slate-800 p-6 rounded-xl shadow-lg border border-slate-700 reveal-on-scroll" data-delay="100">
                    <h3 class="font-bold text-xl text-pink-400 mb-2">Indian Agriculture</h3>
                    <p>In Telangana, the Saagu Baagu initiative used AI-driven advice to help chili farmers. Trust in these explainable insights led to a <span class="text-white font-bold text-3xl">21%</span> increase in crop yield and doubled farmer income.</p>
                </div>
                <div class="bg-slate-800 p-6 rounded-xl shadow-lg border border-slate-700 reveal-on-scroll" data-delay="200">
                    <h3 class="font-bold text-xl text-pink-400 mb-2">Global Finance</h3>
                    <p>By explaining the rationale behind flagged transactions, XAI has helped increase fraud detection rates by a reported <span class="text-white font-bold text-3xl">30%</span> while minimizing false positives that inconvenience customers.</p>
                </div>
            </div>
        </section>

        <section id="frontier" class="mb-20 md:mb-32">
            <div class="text-center max-w-3xl mx-auto mb-12 reveal-on-scroll">
                <h2 class="text-3xl md:text-4xl font-bold text-white mb-4">The New Frontier: Mechanistic Interpretability</h2>
                <p class="text-lg text-slate-400">For Large Language Models (LLMs), we need to go deeper. Mechanistic Interpretability aims to reverse-engineer the model's internal algorithms, identifying "circuits" of neurons that perform specific, understandable tasks.</p>
            </div>
            <div class="bg-slate-800 border border-slate-700 rounded-xl p-8 reveal-on-scroll">
                <h3 class="text-2xl font-bold text-center text-white mb-8">Discovering an Algorithm in the Weights</h3>
                <div class="flex flex-col md:flex-row justify-center items-center gap-4">
                    <div class="flow-step reveal-on-scroll" data-delay="100">
                        <div class="bg-cyan-500 text-white w-24 h-24 rounded-full flex items-center justify-center text-center p-2 text-sm font-bold">1. Causal Tracing</div>
                    </div>
                    <div class="flow-arrow hidden md:block reveal-on-scroll" data-delay="200"></div>
                    <div class="flow-arrow md:hidden reveal-on-scroll" data-delay="200"></div>
                    <div class="flow-step reveal-on-scroll" data-delay="300">
                        <div class="bg-violet-500 text-white w-24 h-24 rounded-full flex items-center justify-center text-center p-2 text-sm font-bold">2. Identify Components</div>
                    </div>
                    <div class="flow-arrow hidden md:block reveal-on-scroll" data-delay="400"></div>
                    <div class="flow-arrow md:hidden reveal-on-scroll" data-delay="400"></div>
                    <div class="flow-step reveal-on-scroll" data-delay="500">
                         <div class="bg-pink-500 text-white w-24 h-24 rounded-full flex items-center justify-center text-center p-2 text-sm font-bold">3. Map the Circuit</div>
                    </div>
                </div>
                <div class="mt-8 pt-6 border-t border-slate-700 reveal-on-scroll">
                    <h4 class="text-lg font-semibold text-center text-white">Example: The IOI Circuit</h4>
                    <p class="text-center text-slate-400 max-w-2xl mx-auto">In "When John and Mary went to the store, John gave a drink to ___", this circuit correctly identifies "Mary" by using specialized 'Name Mover' attention heads to copy her name and 'S-Inhibition' heads to prevent copying "John's" name.</p>
                </div>
            </div>
        </section>
        
        <section id="next-wave" class="mb-20 md:mb-32">
            <div class="text-center max-w-3xl mx-auto mb-12 reveal-on-scroll">
                <h2 class="text-3xl md:text-4xl font-bold text-white mb-4">The Next Wave of XAI</h2>
                <p class="text-lg text-slate-400">The future of XAI is not just about transparency, but about creating explanations that are meaningful, usable, and reliable. Three interconnected frontiers are leading this charge.</p>
            </div>
            <div class="grid grid-cols-1 lg:grid-cols-3 gap-8">
                <div class="bg-slate-800 p-6 rounded-xl shadow-lg border border-slate-700 flex flex-col reveal-on-scroll" data-delay="100">
                    <h3 class="font-bold text-2xl text-white mb-4 text-center">Causal AI</h3>
                    <p class="text-slate-400 mb-6 flex-grow">Moves beyond correlation to provide actionable counterfactuals.Instead of just saying why a decision was made, it explains what could be changed* to alter the outcome.</p>
                    <div class="space-y-4 mt-auto">
                        <div class="bg-red-900/50 border border-red-700 p-4 rounded-lg">
                            <p class="font-semibold text-red-300">Loan: DENIED</p>
                            <p class="text-sm text-red-400">Reason: High debt-to-income ratio.</p>
                        </div>
                        <div class="text-center text-2xl text-violet-400">‚Üì</div>
                        <div class="bg-green-900/50 border border-green-700 p-4 rounded-lg">
                            <p class="font-semibold text-green-300">Counterfactual: APPROVED</p>
                            <p class="text-sm text-green-400">"If monthly debt was reduced by $300."</p>
                        </div>
                    </div>
                </div>
                <div class="bg-slate-800 p-6 rounded-xl shadow-lg border border-slate-700 flex flex-col reveal-on-scroll" data-delay="200">
                    <h3 class="font-bold text-2xl text-white mb-4 text-center">Human-Centered XAI</h3>
                    <p class="text-slate-400 mb-6 flex-grow">Places the user at the center, tailoring explanations to their needs through interactive dialogue. The goal is not just transparency, but genuine human understanding.</p>
                     <div class="space-y-3 mt-auto">
                        <div class="flex justify-end"><p class="bg-violet-600 text-white p-3 rounded-l-lg rounded-br-lg max-w-xs">Why was my claim denied?</p></div>
                        <div class="flex justify-start"><p class="bg-slate-700 text-slate-200 p-3 rounded-r-lg rounded-bl-lg max-w-xs">The model flagged the procedure as 'elective' based on the diagnostic code.</p></div>
                         <div class="flex justify-end"><p class="bg-violet-600 text-white p-3 rounded-l-lg rounded-br-lg max-w-xs">Show me the part of the report that led to that.</p></div>
                    </div>
                </div>
                <div class="bg-slate-800 p-6 rounded-xl shadow-lg border border-slate-700 flex flex-col reveal-on-scroll" data-delay="300">
                    <h3 class="font-bold text-2xl text-white mb-4 text-center">Adversarial Robustness</h3>
                    <p class="text-slate-400 mb-6 flex-grow">Ensures explanations are reliable and can't be manipulated.Adversarial attacks can change an explanation without changing the model's prediction, creating a false sense of trust.</p>
                    <div class="text-center mt-auto">
                        <div class="text-6xl text-pink-500 mb-4">üõ°Ô∏è</div>
                        <p class="font-semibold text-white">A Robust Explanation is Stable</p>
                        <p class="text-slate-400">It should not be possible for a tiny, invisible change to an input to drastically alter the reason given for a decision.</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="research-papers" class="mb-20 md:mb-32">
            <div class="text-center max-w-3xl mx-auto mb-12 reveal-on-scroll">
                <h2 class="text-3xl md:text-4xl font-bold text-white mb-4">Key Research Papers & Links</h2>
                <p class="text-lg text-slate-400">Our work builds upon the foundational and cutting-edge research in the field of Explainable AI. Here are the seminal papers that informed our analysis.</p>
            </div>
            <div class="max-w-4xl mx-auto space-y-4">
                <a href="https://arxiv.org/abs/1602.04938" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="100">
                    <h3 class="font-bold text-violet-400">"Why Should I Trust You?": Explaining the Predictions of Any Classifier (LIME)</h3>
                    <p class="text-sm text-slate-400">Ribeiro, M. T., Singh, S., & Guestrin, C. (2016)</p>
                </a>
                <a href="https://arxiv.org/abs/1705.07874" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="150">
                    <h3 class="font-bold text-violet-400">A Unified Approach to Interpreting Model Predictions (SHAP)</h3>
                    <p class="text-sm text-slate-400">Lundberg, S. M., & Lee, S. I. (2017)</p>
                </a>
                <a href="https://arxiv.org/abs/1610.02391" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="200">
                    <h3 class="font-bold text-violet-400">Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</h3>
                    <p class="text-sm text-slate-400">Selvaraju, R. R., et al. (2017)</p>
                </a>
                <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="250">
                    <h3 class="font-bold text-violet-400">Machine Bias (COMPAS Algorithm)</h3>
                    <p class="text-sm text-slate-400">Angwin, J., Larson, J., Mattu, S., & Kirchner, L. (2016)</p>
                </a>
                <a href="http://proceedings.mlr.press/v81/buolamwini18a.html" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="300">
                    <h3 class="font-bold text-violet-400">Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification</h3>
                    <p class="text-sm text-slate-400">Buolamwini, J., & Gebru, T. (2018)</p>
                </a>
                <a href="https://science.sciencemag.org/content/366/6464/447" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="350">
                    <h3 class="font-bold text-violet-400">Dissecting racial bias in an algorithm used to manage the health of populations</h3>
                    <p class="text-sm text-slate-400">Obermeyer, Z., et al. (2019)</p>
                </a>
                <a href="https://distill.pub/2020/circuits/zoom-in/" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="400">
                    <h3 class="font-bold text-violet-400">Zoom In: An Introduction to Circuits</h3>
                    <p class="text-sm text-slate-400">Olah, C., et al. (2020)</p>
                </a>
                <a href="https://arxiv.org/abs/2211.00593" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="450">
                    <h3 class="font-bold text-violet-400">Interpretability in the Wild: A Circuit for Indirect Object Identification in GPT-2</h3>
                    <p class="text-sm text-slate-400">Wang, K., et al. (2022)</p>
                </a>
                <a href="https://transformer-circuits.pub/2021/framework/index.html" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="500">
                    <h3 class="font-bold text-violet-400">A Mathematical Framework for Transformer Circuits</h3>
                    <p class="text-sm text-slate-400">Elhage, N., et al. (2021)</p>
                </a>
                <a href="https://arxiv.org/abs/2201.11903" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="550">
                    <h3 class="font-bold text-violet-400">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</h3>
                    <p class="text-sm text-slate-400">Wei, J., et al. (2022)</p>
                </a>
                <a href="https://jolt.law.harvard.edu/assets/articlePDFs/v31/31HarvJLTech841.pdf" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="600">
                    <h3 class="font-bold text-violet-400">Counterfactual explanations without opening the black box: Automated decisions and the GDPR</h3>
                    <p class="text-sm text-slate-400">Wachter, S., Mittelstadt, B., & Russell, C. (2017)</p>
                </a>
                <a href="https://arxiv.org/abs/1706.07269" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="650">
                    <h3 class="font-bold text-violet-400">Explanation in Artificial Intelligence: Insights from the Social Sciences</h3>
                    <p class="text-sm text-slate-400">Miller, T. (2019)</p>
                </a>
                <a href="https://arxiv.org/abs/1906.07983" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="700">
                    <h3 class="font-bold text-violet-400">Explanations can be manipulated and geometry is to blame</h3>
                    <p class="text-sm text-slate-400">Dombrowski, A. K., et al. (2019)</p>
                </a>
                <a href="https://arxiv.org/abs/1702.08608" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="750">
                    <h3 class="font-bold text-violet-400">Towards A Rigorous Science of Interpretable Machine Learning</h3>
                    <p class="text-sm text-slate-400">Doshi-Velez, F., & Kim, B. (2017)</p>
                </a>
                <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="800">
                    <h3 class="font-bold text-violet-400">EU AI Act (Proposal for a Regulation)</h3>
                    <p class="text-sm text-slate-400">European Commission (2021)</p>
                </a>
                <a href="https://www.niti.gov.in/sites/default/files/2021-02/Responsible-AI-22022021.pdf" target="_blank" class="block bg-slate-800 p-4 rounded-lg hover:bg-slate-700 transition-all duration-300 transform hover:scale-105 border border-slate-700 reveal-on-scroll" data-delay="850">
                    <h3 class="font-bold text-violet-400">Responsible AI for All: Adopting the Framework</h3>
                    <p class="text-sm text-slate-400">NITI Aayog, Government of India (2021)</p>
                </a>
            </div>
        </section>

        <section id="team" class="mb-20 md:mb-32">
            <div class="text-center max-w-3xl mx-auto mb-12 reveal-on-scroll">
                <h2 class="text-3xl md:text-4xl font-bold text-white mb-4">Research By Our Team</h2>
                <p class="text-lg text-slate-400">This work is the result of a collaborative effort by a dedicated team of researchers.</p>
            </div>
            <div class="grid grid-cols-2 md:grid-cols-3 lg:grid-cols-5 gap-8 md:gap-12">
                <div class="team-member reveal-on-scroll" data-delay="100">
                    <div class="blob-container">
                        <img src="./assets/img2.jpg" alt="Team Member 1" class="blob-image">
                    </div>
                    <h3 class="text-lg font-bold text-white mt-4">Razab Nisha Y</h3>
                    <p class="text-sm text-violet-400">B.Sc Computer Technology</p>
                    <p class="text-xs text-slate-500">Rathinam College of Arts and Science</p>
                </div>
                <div class="team-member reveal-on-scroll" data-delay="200">
                    <div class="blob-container">
                        <img src="./assets/img4.jpg" alt="Team Member 2" class="blob-image">
                    </div>
                    <h3 class="text-lg font-bold text-white mt-4">Kaviya Sri T</h3>
                    <p class="text-sm text-violet-400">B.Sc Computer Technology</p>
                    <p class="text-xs text-slate-500">Rathinam College of Arts and Science</p>
                </div>
                <div class="team-member reveal-on-scroll" data-delay="300">
                    <div class="blob-container">
                        <img src="./assets/img1.jpg" alt="Team Member 3" class="blob-image">
                    </div>
                    <h3 class="text-lg font-bold text-white mt-4">Dhina GS</h3>
                    <p class="text-sm text-violet-400">B.Sc CyberSecurity</p>
                    <p class="text-xs text-slate-500">Rathinam College of Arts and Science</p>
                </div>
                <div class="team-member reveal-on-scroll" data-delay="400">
                    <div class="blob-container">
                        <img src="./assets/img3.jpg" alt="Team Member 4" class="blob-image">
                    </div>
                    <h3 class="text-lg font-bold text-white mt-4">Harish Rohith S</h3>
                    <p class="text-sm text-violet-400">B.Sc Computer Technology</p>
                    <p class="text-xs text-slate-500">Rathinam College of Arts and Science</p>
                </div>
                <div class="team-member reveal-on-scroll" data-delay="500">
                    <div class="blob-container">
                         <img src="./assets/img5.jpg" alt="Team Member 5" class="blob-image">
                    </div>
                    <h3 class="text-lg font-bold text-white mt-4">Karthikeyan T</h3>
                    <p class="text-sm text-violet-400">B.Sc Computer Science</p>
                    <p class="text-xs text-slate-500">Rathinam College of Arts and Science</p>
                </div>
            </div>
        </section>


        <footer class="text-center pt-12 border-t border-slate-700 max-w-3xl mx-auto reveal-on-scroll">
             <h3 class="text-2xl font-bold text-white mb-4">Conclusion: A Call to Action for an Explainable Future</h3>
            <p class="text-slate-400">The future of trustworthy AI is not just about performance; it's about partnership. Neglecting XAI invites a future of unchecked bias, eroded trust, and a dangerous accountability gap. The ethical imperative for responsible AI is not a constraint, but a catalyst for better, more robust, and more widely adopted systems that serve humanity with transparency and trust.</p>
        </footer>

    </main>
    
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            // --- Animated Background ---
            const canvas = document.getElementById('background-canvas');
            const ctx = canvas.getContext('2d');
            let particles = [];

            const setCanvasSize = () => {
                canvas.width = window.innerWidth;
                canvas.height = window.innerHeight;
            };

            const createParticles = () => {
                particles = [];
                const particleCount = Math.floor((canvas.width * canvas.height) / 20000);
                for (let i = 0; i < particleCount; i++) {
                    particles.push({
                        x: Math.random() * canvas.width,
                        y: Math.random() * canvas.height,
                        vx: (Math.random() - 0.5) * 0.5,
                        vy: (Math.random() - 0.5) * 0.5,
                        radius: Math.random() * 1.5 + 1,
                    });
                }
            };

            const animate = () => {
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                particles.forEach(p => {
                    p.x += p.vx;
                    p.y += p.vy;

                    if (p.x < 0 || p.x > canvas.width) p.vx *= -1;
                    if (p.y < 0 || p.y > canvas.height) p.vy *= -1;

                    ctx.beginPath();
                    ctx.arc(p.x, p.y, p.radius, 0, Math.PI * 2);
                    ctx.fillStyle = 'rgba(167, 139, 250, 0.5)';
                    ctx.fill();
                });

                for (let i = 0; i < particles.length; i++) {
                    for (let j = i + 1; j < particles.length; j++) {
                        const dist = Math.hypot(particles[i].x - particles[j].x, particles[i].y - particles[j].y);
                        if (dist < 120) {
                            ctx.beginPath();
                            ctx.moveTo(particles[i].x, particles[i].y);
                            ctx.lineTo(particles[j].x, particles[j].y);
                            ctx.strokeStyle = `rgba(167, 139, 250, ${1 - dist / 120})`;
                            ctx.lineWidth = 0.5;
                            ctx.stroke();
                        }
                    }
                }

                requestAnimationFrame(animate);
            };
            
            setCanvasSize();
            createParticles();
            animate();

            window.addEventListener('resize', () => {
                setCanvasSize();
                createParticles();
            });

            // --- Chart and Scroll Animation Logic ---
            const wrapLabel = (label, maxWidth) => {
                if (typeof label !== 'string') return [String(label)];
                const words = label.split(' ');
                let lines = [];
                let currentLine = '';
                for (const word of words) {
                    if ((currentLine + ' ' + word).length > maxWidth) {
                        if (currentLine.length > 0) lines.push(currentLine);
                        currentLine = word;
                    } else {
                        currentLine += (currentLine.length > 0 ? ' ' : '') + word;
                    }
                }
                if (currentLine.length > 0) lines.push(currentLine);
                return lines;
            };
            
            const tooltipTitleCallback = (tooltipItems) => {
                const item = tooltipItems[0];
                let label = item.chart.data.labels[item.dataIndex];
                if (Array.isArray(label)) {
                    return label.join(' ');
                }
                return label;
            };

            const energeticPlayful = ['#38BDF8', '#A78BFA', '#F472B6', '#34D399', '#FBBF24'];

            const createXaiTechniquesChart = () => {
                const xaiTechniquesCtx = document.getElementById('xaiTechniquesChart').getContext('2d');
                new Chart(xaiTechniquesCtx, {
                    type: 'radar',
                    data: {
                        labels: ['Flexibility (Agnostic)', 'Theoretical Soundness', 'Computational Efficiency', 'Scope (Global)', 'Visual Intuition'],
                        datasets: [{
                            label: 'LIME',
                            data: [5, 2, 4, 1, 4],
                            fill: true,
                            backgroundColor: 'rgba(56, 189, 248, 0.2)',
                            borderColor: energeticPlayful[0],
                            pointBackgroundColor: energeticPlayful[0],
                        }, {
                            label: 'SHAP',
                            data: [4, 5, 2, 5, 3],
                            fill: true,
                            backgroundColor: 'rgba(167, 139, 250, 0.2)',
                            borderColor: energeticPlayful[1],
                            pointBackgroundColor: energeticPlayful[1],
                        }, {
                            label: 'Grad-CAM',
                            data: [1, 3, 5, 1, 5],
                            fill: true,
                            backgroundColor: 'rgba(244, 114, 182, 0.2)',
                            borderColor: energeticPlayful[2],
                            pointBackgroundColor: energeticPlayful[2],
                        }]
                    },
                    options: {
                        maintainAspectRatio: false,
                        scales: {
                            r: {
                                angleLines: { color: 'rgba(255, 255, 255, 0.2)' },
                                grid: { color: 'rgba(255, 255, 255, 0.2)' },
                                pointLabels: { color: '#CBD5E1', font: { size: 12 } },
                                ticks: {
                                    color: '#94A3B8',
                                    backdropColor: 'transparent',
                                    stepSize: 1,
                                },
                                suggestedMin: 0,
                                suggestedMax: 5
                            }
                        },
                        plugins: {
                            legend: {
                                labels: {
                                    color: '#CBD5E1'
                                }
                            },
                            tooltip: {
                                callbacks: {
                                   title: tooltipTitleCallback
                                }
                            }
                        }
                    }
                });
            };

            const createImpactChart = () => {
                const impactCtx = document.getElementById('impactChart').getContext('2d');
                const impactLabels = [
                    'Enhanced Diagnostic Confidence (Healthcare)',
                    'Improved Patient Understanding (Healthcare)',
                    'Increased Fraud Detection (Finance)',
                    'Reduced Algorithmic Bias (Retail)',
                    'Optimized Resource Use (Agriculture)',
                    'Enhanced Accountability (Public Sector)'
                ];
                new Chart(impactCtx, {
                    type: 'bar',
                    data: {
                        labels: impactLabels.map(label => wrapLabel(label, 20)),
                        datasets: [{
                            label: 'Positive Impact Score (Illustrative)',
                            data: [85, 90, 75, 70, 95, 80],
                            backgroundColor: [
                                'rgba(56, 189, 248, 0.7)',
                                'rgba(167, 139, 250, 0.7)',
                                'rgba(244, 114, 182, 0.7)',
                                'rgba(52, 211, 153, 0.7)',
                                'rgba(251, 191, 36, 0.7)',
                                'rgba(56, 189, 248, 0.5)'
                            ],
                            borderColor: energeticPlayful,
                            borderWidth: 1
                        }]
                    },
                    options: {
                        indexAxis: 'y',
                        maintainAspectRatio: false,
                        scales: {
                            x: {
                                grid: { color: 'rgba(255, 255, 255, 0.1)' },
                                ticks: { color: '#CBD5E1' }
                            },
                            y: {
                                grid: { display: false },
                                ticks: { color: '#CBD5E1' }
                            }
                        },
                        plugins: {
                            legend: {
                                display: false
                            },
                            tooltip: {
                                callbacks: {
                                   title: tooltipTitleCallback
                                }
                            }
                        }
                    }
                });
            };

            // Intersection Observer for animations
            const observer = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        const delay = entry.target.dataset.delay || 0;
                        setTimeout(() => {
                            entry.target.classList.add('revealed');
                        }, delay);

                        // If the intersecting element is a chart canvas, create the chart
                        if (entry.target.id === 'xaiTechniquesChart' && !Chart.getChart(entry.target)) {
                            createXaiTechniquesChart();
                        }
                        if (entry.target.id === 'impactChart' && !Chart.getChart(entry.target)) {
                            createImpactChart();
                        }

                        observer.unobserve(entry.target);
                    }
                });
            }, {
                threshold: 0.1
            });

            const elementsToReveal = document.querySelectorAll('.reveal-on-scroll');
            elementsToReveal.forEach(el => observer.observe(el));
            
            // Observe chart containers specifically to trigger their creation
            const chartContainers = document.querySelectorAll('canvas');
            chartContainers.forEach(canvas => {
                if(canvas.id !== 'background-canvas') {
                    observer.observe(canvas);
                }
            });
        });
    </script>
</body>
</html>
